{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b9c5fb1-92cb-4eb5-b489-ee4d1f661d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/MilesCranmer/SymbolicRegression.jl.git`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.8/Project.toml`\n",
      " \u001b[90m [8254be44] \u001b[39m\u001b[93m~ SymbolicRegression v0.22.4 ⇒ v0.22.2 `https://github.com/MilesCranmer/SymbolicRegression.jl.git#support-extra-data`\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.8/Manifest.toml`\n",
      " \u001b[90m [8254be44] \u001b[39m\u001b[93m~ SymbolicRegression v0.22.4 ⇒ v0.22.2 `https://github.com/MilesCranmer/SymbolicRegression.jl.git#support-extra-data`\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39mSymbolicRegression\n",
      "  1 dependency successfully precompiled in 42 seconds. 266 already precompiled.\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.add(url = \"https://github.com/MilesCranmer/SymbolicRegression.jl.git\", rev = \"support-extra-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd3c689-1c67-4bb2-a354-f539dbf47084",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ  # for fit/predict\n",
    "using SymbolicRegression  # for SRRegressor\n",
    "using Zygote  # For `enable_autodiff=true`\n",
    "using SymbolicUtils\n",
    "using NPZ\n",
    "using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf556f48-a430-4f2d-9120-1e71287c057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deriv_f (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_f(x) = x^3 / 3 - cos(x)\n",
    "deriv_f(x) = x^2 + sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c38a5f92-cbf5-4d6f-b6bc-ab9bedef94da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32-element Vector{Float64}:\n",
       "  0.0\n",
       "  0.41696656061611775\n",
       "  1.006795441362392\n",
       "  1.7407915683009982\n",
       "  2.596415860289225\n",
       "  3.5595736030415055\n",
       "  4.626045473685325\n",
       "  5.801915925084421\n",
       "  7.102955436427127\n",
       "  8.55301934966111\n",
       " 10.181625856572422\n",
       " 12.020959041455523\n",
       " 14.102601257946091\n",
       "  ⋮\n",
       " 41.0765492048505\n",
       " 45.58145539714299\n",
       " 50.248209128707636\n",
       " 55.050052009553035\n",
       " 59.96730333407156\n",
       " 64.98935824662338\n",
       " 70.11576444366216\n",
       " 75.35626809573589\n",
       " 80.7298243269406\n",
       " 86.26267271702045\n",
       " 91.98567321877702\n",
       " 97.93117297286523"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reshape(0.0:0.32:10.0, :, 1)\n",
    "y = true_f.(X[:, 1])\n",
    "∂y = deriv_f.(X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fad36d59-57e3-4259-9aaf-65e11eb7774e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "derivative_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function derivative_loss(tree, dataset::Dataset{T,L}, options, idx) where {T,L}\n",
    "    # Select from the batch indices, if given\n",
    "    X = idx === nothing ? dataset.X : view(dataset.X, :, idx)\n",
    "\n",
    "    # Evaluate both f(x) and f'(x), where f is defined by `tree`\n",
    "    ŷ, ∂ŷ, completed = eval_grad_tree_array(tree, X, options; variable=true)\n",
    "\n",
    "    #println(size(dataset.extra.∂y))\n",
    "\n",
    "    !completed && return L(Inf)\n",
    "\n",
    "    y = idx === nothing ? dataset.y : view(dataset.y, idx)\n",
    "    ∂y = idx === nothing ? dataset.extra.∂y : view(dataset.extra.∂y, idx)\n",
    "\n",
    "    mse_deriv = sum(i -> (∂ŷ[i] - ∂y[i])^2, eachindex(∂y)) / length(∂y)\n",
    "    mse_value = sum(i -> (ŷ[i] - y[i])^2, eachindex(y)) / length(y)\n",
    "\n",
    "    return mse_value  + mse_deriv\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2939d67f-5a44-4d2d-a2dc-71193d1806e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc SymbolicRegression.SRRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{AbstractMatrix{Continuous}, AbstractVector{Continuous}, Table{AbstractVector{Continuous}}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Union{Tuple{Union{Table{<:AbstractVector{<:Continuous}}, AbstractMatrix{<:Continuous}}, AbstractVector{<:Continuous}}, Tuple{Union{Table{<:AbstractVector{<:Continuous}}, AbstractMatrix{<:Continuous}}, AbstractVector{<:Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/ByFwA/src/machines.jl:230\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(SRRegressor(binary_operators = Function[+, -, *], …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mYou are using an experimental interface for the `extra` field of a `Dataset` type. This API may change in the future.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SymbolicRegression.MLJInterfaceModule ~/.julia/packages/SymbolicRegression/fHd3u/src/MLJInterface.jl:208\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mYou are using multithreading mode, but only one thread is available. Try starting julia with `--threads=auto`.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SymbolicRegression ~/.julia/packages/SymbolicRegression/fHd3u/src/SymbolicRegression.jl:553\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "model = SRRegressor(;\n",
    "    binary_operators=[+, -, *],\n",
    "    unary_operators=[cos],\n",
    "    loss_function=derivative_loss,\n",
    "    enable_autodiff=true,\n",
    "    batching=true,\n",
    "    batch_size=25,\n",
    "    niterations=100,\n",
    "    early_stop_condition=1e-6,\n",
    ")\n",
    "mach = machine(model, X, y, (; ∂y=∂y))\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8235ac-9c4d-4fc1-b478-c9492cc1d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the eta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c620c0fa-e094-472c-a79b-a5b8e8b1fcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = npzread(\"toyproblem_sr_data.npz\")\n",
    "\n",
    "skip = 5\n",
    "finish = 3000\n",
    "\n",
    "X = datafile[\"theta\"][1:skip:finish, :]\n",
    "y = datafile[\"eta\"][1:skip:finish, :]\n",
    "∂y = datafile[\"jacobians\"][1:skip:finish, :, :]\n",
    "\n",
    "size(X), size(y), size(∂y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aa8159e-28cf-4549-8314-9563c44f01ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/lucas/repositories/degen_discovery/toy_problem\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44175913-eb6f-45f6-abba-afffc2b2eaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc SymbolicRegression.SRRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{AbstractMatrix{Continuous}, AbstractVector{Continuous}, Unknown}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Union{Tuple{Union{Table{<:AbstractVector{<:Continuous}}, AbstractMatrix{<:Continuous}}, AbstractVector{<:Continuous}}, Tuple{Union{Table{<:AbstractVector{<:Continuous}}, AbstractMatrix{<:Continuous}}, AbstractVector{<:Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/ByFwA/src/machines.jl:230\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(SRRegressor(binary_operators = Function[+, *, ^], …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mYou are using an experimental interface for the `extra` field of a `Dataset` type. This API may change in the future.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SymbolicRegression.MLJInterfaceModule ~/.julia/packages/SymbolicRegression/fHd3u/src/MLJInterface.jl:208\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mYou are using multithreading mode, but only one thread is available. Try starting julia with `--threads=auto`.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SymbolicRegression ~/.julia/packages/SymbolicRegression/fHd3u/src/SymbolicRegression.jl:553\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "model = SRRegressor(;\n",
    "    binary_operators=[+, *, ^],\n",
    "    unary_operators=[log],\n",
    "    constraints=[(^)=>(-1, 9)],\n",
    "    nested_constraints=[(^) => [(^) => 0, log => 0],\n",
    "                   log => [(^) =>  0, log => 0],\n",
    "            #        exp => [log => 0]\n",
    "        ],\n",
    "    loss_function=derivative_loss,\n",
    "    enable_autodiff=true,\n",
    "    batching=false,\n",
    "    #batch_size=100,\n",
    "    niterations=100,\n",
    "    parsimony=100,\n",
    ")\n",
    "mach = machine(model, X, y[:, 1], (; ∂y=∂y[:, 1, :]))\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59adb52e-aa79-4bd0-9925-dcce90f31615",
   "metadata": {},
   "source": [
    "## loss for fitting $y=\\partial y$\n",
    "here we want to pass the derivatives as an extra and fit the candidate expression to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea86784-134d-4755-8ae7-0af56f11680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function fit_derivative_loss(tree, dataset::Dataset{T,L}, options, idx) where {T,L}\n",
    "    # Column-major:\n",
    "    X = idx === nothing ? dataset.X : view(dataset.X, :, idx)\n",
    "    #∂y = idx === nothing ? dataset.y : view(dataset.y, idx)\n",
    "\n",
    "    ŷ, ∂ŷ, completed = eval_grad_tree_array(tree, X, options; variable=true)\n",
    "\n",
    "    !completed && return L(Inf)\n",
    "\n",
    "    y = idx === nothing ? dataset.y : view(dataset.y, idx)\n",
    "    ∂y = idx === nothing ? dataset.extra.∂y : view(dataset.extra.∂y, idx)\n",
    "    \n",
    "    # match the derivative only\n",
    "    mse = sum(i -> (∂ŷ[i] - ∂y[i])^2, eachindex(∂y)) / length(∂y)\n",
    "    \n",
    "    return mse\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2f5d3c-d018-407d-9bfe-c9c0594c18bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRRegressor(;\n",
    "    binary_operators=[+, *, ^],\n",
    "    unary_operators=[log],\n",
    "    constraints=[(^)=>(-1, 9)],\n",
    "    nested_constraints=[(^) => [(^) => 0, log => 0],\n",
    "                   log => [(^) =>  0, log => 0],\n",
    "            #        exp => [log => 0]\n",
    "        ],\n",
    "    loss_function=fit_derivative_loss,\n",
    "    enable_autodiff=true,\n",
    "    #batching=false,\n",
    "    batch_size=25,\n",
    "    niterations=100,\n",
    "    parsimony=100,\n",
    ")\n",
    "mach = machine(model, X, y[:, 1], (; ∂y=∂y[:, 1, :]))\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f98316-027d-456a-948e-82b778ae04c4",
   "metadata": {},
   "source": [
    "# run script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b6d3e1-6f0f-45b3-a9dc-e5cf5754da57",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ  # for fit/predict\n",
    "using SymbolicRegression  # for SRRegressor\n",
    "using Zygote  # For `enable_autodiff=true`\n",
    "using SymbolicUtils\n",
    "using NPZ\n",
    "using Pandas\n",
    "\n",
    "\n",
    "function fit_derivative_loss(tree, dataset::Dataset{T,L}, options, idx) where {T,L}\n",
    "    # Column-major:\n",
    "    X = idx === nothing ? dataset.X : view(dataset.X, :, idx)\n",
    "    #∂y = idx === nothing ? dataset.y : view(dataset.y, idx)\n",
    "\n",
    "    ŷ, ∂ŷ, completed = eval_grad_tree_array(tree, X, options; variable=true)\n",
    "\n",
    "    !completed && return L(Inf)\n",
    "\n",
    "    y = idx === nothing ? dataset.y : view(dataset.y, idx)\n",
    "    ∂y = idx === nothing ? dataset.extra.∂y : view(dataset.extra.∂y, idx)\n",
    "    \n",
    "    # match the derivative only\n",
    "    mse = sum(i -> (∂ŷ[i] - ∂y[i])^2, eachindex(∂y)) / length(∂y)\n",
    "    \n",
    "    return mse\n",
    "end\n",
    "\n",
    "\n",
    "function derivative_loss(tree, dataset::Dataset{T,L}, options, idx) where {T,L}\n",
    "    # Select from the batch indices, if given\n",
    "    X = idx === nothing ? dataset.X : view(dataset.X, :, idx)\n",
    "\n",
    "    # Evaluate both f(x) and f'(x), where f is defined by `tree`\n",
    "    ŷ, ∂ŷ, completed = eval_grad_tree_array(tree, X, options; variable=true)\n",
    "\n",
    "    #println(size(dataset.extra.∂y))\n",
    "\n",
    "    !completed && return L(Inf)\n",
    "\n",
    "    y = idx === nothing ? dataset.y : view(dataset.y, idx)\n",
    "    ∂y = idx === nothing ? dataset.extra.∂y : view(dataset.extra.∂y, idx)\n",
    "\n",
    "    mse_deriv = sum(i -> (∂ŷ[i] - ∂y[i])^2, eachindex(∂y)) / length(∂y)\n",
    "    mse_value = sum(i -> (ŷ[i] - y[i])^2, eachindex(y)) / length(y)\n",
    "\n",
    "    return  mse_deriv * mse_value\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "datafile = npzread(\"toyproblem_sr_data2.npz\")\n",
    "\n",
    "skip = 5\n",
    "finish = 3000\n",
    "\n",
    "X = datafile[\"theta\"][1:skip:finish, :]\n",
    "y = datafile[\"eta\"][1:skip:finish, :]\n",
    "∂y = datafile[\"jacobians\"][1:skip:finish, :, :]\n",
    "\n",
    "size(X), size(y), size(∂y)\n",
    "\n",
    "\n",
    "\n",
    "# choose which variable to do\n",
    "\n",
    "idx = 2\n",
    "\n",
    "model = SRRegressor(;\n",
    "    binary_operators=[+, *, ^],\n",
    "    unary_operators=[log, sqrt],\n",
    "    constraints=[(^)=>(-1, 9)],\n",
    "    #nested_constraints=[(^) => [(^) => 0, log => 0],\n",
    "    #               log => [(^) =>  0, log => 0],\n",
    "                #    exp => [log => 0]\n",
    "    #    ],\n",
    "    loss_function=fit_derivative_loss,\n",
    "    enable_autodiff=true,\n",
    "    #batching=false,\n",
    "    batch_size=30,\n",
    "    niterations=100,\n",
    "    #parsimony=100,\n",
    ")\n",
    "mach = machine(model, X, y[:, idx], (; ∂y=∂y[:, idx, :]))\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0d94d-2903-44f2-b88b-272616b87954",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
