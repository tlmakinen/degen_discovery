{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c5fb1-92cb-4eb5-b489-ee4d1f661d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.add(url = \"https://github.com/MilesCranmer/SymbolicRegression.jl.git\", rev = \"support-extra-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bd3c689-1c67-4bb2-a354-f539dbf47084",
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLJ  # for fit/predict\n",
    "using SymbolicRegression  # for SRRegressor\n",
    "using Zygote  # For `enable_autodiff=true`\n",
    "using SymbolicUtils\n",
    "using NPZ\n",
    "using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf556f48-a430-4f2d-9120-1e71287c057b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deriv_f (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_f(x) = x^3 / 3 - cos(x)\n",
    "deriv_f(x) = x^2 + sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c38a5f92-cbf5-4d6f-b6bc-ab9bedef94da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32-element Vector{Float64}:\n",
       "  0.0\n",
       "  0.41696656061611775\n",
       "  1.006795441362392\n",
       "  1.7407915683009982\n",
       "  2.596415860289225\n",
       "  3.5595736030415055\n",
       "  4.626045473685325\n",
       "  5.801915925084421\n",
       "  7.102955436427127\n",
       "  8.55301934966111\n",
       " 10.181625856572422\n",
       " 12.020959041455523\n",
       " 14.102601257946091\n",
       "  ⋮\n",
       " 41.0765492048505\n",
       " 45.58145539714299\n",
       " 50.248209128707636\n",
       " 55.050052009553035\n",
       " 59.96730333407156\n",
       " 64.98935824662338\n",
       " 70.11576444366216\n",
       " 75.35626809573589\n",
       " 80.7298243269406\n",
       " 86.26267271702045\n",
       " 91.98567321877702\n",
       " 97.93117297286523"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = reshape(0.0:0.32:10.0, :, 1)\n",
    "y = true_f.(X[:, 1])\n",
    "∂y = deriv_f.(X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad36d59-57e3-4259-9aaf-65e11eb7774e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "derivative_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function derivative_loss(tree, dataset::Dataset{T,L}, options, idx) where {T,L}\n",
    "    # Select from the batch indices, if given\n",
    "    X = idx === nothing ? dataset.X : view(dataset.X, :, idx)\n",
    "\n",
    "    # Evaluate both f(x) and f'(x), where f is defined by `tree`\n",
    "    ŷ, ∂ŷ, completed = eval_grad_tree_array(tree, X, options; variable=true)\n",
    "\n",
    "    #println(size(dataset.extra.∂y))\n",
    "\n",
    "    !completed && return L(Inf)\n",
    "\n",
    "    y = idx === nothing ? dataset.y : view(dataset.y, idx)\n",
    "    ∂y = idx === nothing ? dataset.extra.∂y : view(dataset.extra.∂y, idx)\n",
    "\n",
    "    mse_deriv = sum(i -> (∂ŷ[i] - ∂y[i])^2, eachindex(∂y)) / length(∂y)\n",
    "    mse_value = sum(i -> (ŷ[i] - y[i])^2, eachindex(y)) / length(y)\n",
    "\n",
    "    return mse_value  + mse_deriv\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2939d67f-5a44-4d2d-a2dc-71193d1806e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc SymbolicRegression.SRRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{AbstractMatrix{Continuous}, AbstractVector{Continuous}, Table{AbstractVector{Continuous}}}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Union{Tuple{Union{Table{<:AbstractVector{<:Continuous}}, AbstractMatrix{<:Continuous}}, AbstractVector{<:Continuous}}, Tuple{Union{Table{<:AbstractVector{<:Continuous}}, AbstractMatrix{<:Continuous}}, AbstractVector{<:Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/ByFwA/src/machines.jl:230\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(SRRegressor(binary_operators = Function[+, -, *], …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mYou are using an experimental interface for the `extra` field of a `Dataset` type. This API may change in the future.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SymbolicRegression.MLJInterfaceModule ~/.julia/packages/SymbolicRegression/fHd3u/src/MLJInterface.jl:208\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mYou are using multithreading mode, but only one thread is available. Try starting julia with `--threads=auto`.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SymbolicRegression ~/.julia/packages/SymbolicRegression/fHd3u/src/SymbolicRegression.jl:553\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0%┣                                           ┫ 0/1.5k [00:01<-25:-34, -1s/it]Expressions evaluated per second: [.....]. Head worker occupation: 0.0%         Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.564e+02  5.623e-01  y = (((x₁ + x₁) + x₁) * x₁)                   9           6.000e+02  1.158e-01  y = (((x₁ + x₁) + x₁) * (x₁ - 0.84207))       10          5.965e+02  5.925e-03  y = (((x₁ + x₁) + x₁) * (x₁ - cos(0.84207)))  11          5.433e+02  9.335e-02  y = (((x₁ + (x₁ * 1.2976)) + x₁) * (x₁ - 0.84207))                                                                            13          4.783e+02  6.380e-02  y = ((((x₁ + (x₁ * 1.2976)) + -0.96141) + x₁) * (x₁ - 0.84207)...                                                                                               )                                             16          4.686e+02  6.822e-03  y = ((((((x₁ - cos(x₁)) + (x₁ + -0.47769)) + x₁) * x₁) + -0.96...                                                                                               477) - x₁)                                    ---------------------------------------------------------------------------------------------------\n",
      "0.1%┣                                              ┫ 2/1.5k [00:01<31:09, 1s/it]Expressions evaluated per second: 2.32e+03. Head worker occupation: 0.8%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.564e+02  5.623e-01  y = (((x₁ + x₁) + x₁) * x₁)                   9           6.000e+02  1.158e-01  y = (((x₁ + x₁) + x₁) * (x₁ - 0.84207))       10          5.965e+02  5.925e-03  y = (((x₁ + x₁) + x₁) * (x₁ - cos(0.84207)))  11          5.433e+02  9.335e-02  y = (((x₁ + (x₁ * 1.2976)) + x₁) * (x₁ - 0.84207))                                                                            12          4.931e+02  9.708e-02  y = (((x₁ * ((x₁ + x₁) + x₁)) - cos(x₁)) - 18.609)                                                                            13          4.783e+02  3.052e-02  y = ((((x₁ + (x₁ * 1.2976)) + -0.96141) + x₁) * (x₁ - 0.84207)...                                                                                               )                                             16          4.686e+02  6.822e-03  y = ((((((x₁ - cos(x₁)) + (x₁ + -0.47769)) + x₁) * x₁) + -0.96...                                                                                               477) - x₁)                                    17          3.893e+02  1.852e-01  y = (x₁ * ((((((x₁ + -1.2292) - cos(x₁)) - cos(x₁)) + x₁) + x₁...                                                                                               ) - 1.9119))                                  19          1.368e+02  5.228e-01  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "0.3%┣▏                                             ┫ 5/1.5k [00:01<08:20, 3it/s]Expressions evaluated per second: 2.32e+03. Head worker occupation: 1.3%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.564e+02  5.623e-01  y = (((x₁ + x₁) + x₁) * x₁)                   9           6.000e+02  1.158e-01  y = (((x₁ + x₁) + x₁) * (x₁ - 0.84207))       10          5.965e+02  5.925e-03  y = (((x₁ + x₁) + x₁) * (x₁ - cos(0.84207)))  11          5.433e+02  9.335e-02  y = (((x₁ + (x₁ * 1.2976)) + x₁) * (x₁ - 0.84207))                                                                            12          4.931e+02  9.708e-02  y = (((x₁ * ((x₁ + x₁) + x₁)) - cos(x₁)) - 18.609)                                                                            13          4.783e+02  3.052e-02  y = ((((x₁ + (x₁ * 1.2976)) + -0.96141) + x₁) * (x₁ - 0.84207)...                                                                                               )                                             16          4.686e+02  6.822e-03  y = ((((((x₁ - cos(x₁)) + (x₁ + -0.47769)) + x₁) * x₁) + -0.96...                                                                                               477) - x₁)                                    17          3.893e+02  1.852e-01  y = (x₁ * ((((((x₁ + -1.2292) - cos(x₁)) - cos(x₁)) + x₁) + x₁...                                                                                               ) - 1.9119))                                  19          1.368e+02  5.228e-01  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "0.5%┣▎                                             ┫ 8/1.5k [00:01<05:12, 5it/s]Expressions evaluated per second: 2.32e+03. Head worker occupation: 1.5%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.564e+02  5.623e-01  y = (((x₁ + x₁) + x₁) * x₁)                   9           5.217e+02  1.857e-01  y = (((x₁ * 1.5734) - 1.5179) * (x₁ + x₁))    12          4.931e+02  1.880e-02  y = (((x₁ * ((x₁ + x₁) + x₁)) - cos(x₁)) - 18.609)                                                                            13          4.783e+02  3.052e-02  y = ((((x₁ + (x₁ * 1.2976)) + -0.96141) + x₁) * (x₁ - 0.84207)...                                                                                               )                                             14          4.384e+02  8.695e-02  y = (((x₁ + x₁) * x₁) + ((x₁ * cos(0.67197 * x₁)) * x₁))                                                                      16          3.360e+02  1.331e-01  y = ((((x₁ - -1.769) + x₁) * x₁) + ((x₁ * cos(0.67197 * x₁)) *...                                                                                                x₁))                                         19          1.368e+02  2.994e-01  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "0.7%┣▎                                            ┫ 10/1.5k [00:02<04:18, 6it/s]Expressions evaluated per second: 2.32e+03. Head worker occupation: 1.4%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.564e+02  5.623e-01  y = (((x₁ + x₁) + x₁) * x₁)                   9           5.217e+02  1.857e-01  y = (((x₁ * 1.5734) - 1.5179) * (x₁ + x₁))    12          4.931e+02  1.880e-02  y = (((x₁ * ((x₁ + x₁) + x₁)) - cos(x₁)) - 18.609)                                                                            13          4.783e+02  3.052e-02  y = ((((x₁ + (x₁ * 1.2976)) + -0.96141) + x₁) * (x₁ - 0.84207)...                                                                                               )                                             14          4.384e+02  8.695e-02  y = (((x₁ + x₁) * x₁) + ((x₁ * cos(0.67197 * x₁)) * x₁))                                                                      16          3.360e+02  1.331e-01  y = ((((x₁ - -1.769) + x₁) * x₁) + ((x₁ * cos(0.67197 * x₁)) *...                                                                                                x₁))                                         19          1.368e+02  2.994e-01  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "0.9%┣▍                                            ┫ 13/1.5k [00:02<03:24, 7it/s]Expressions evaluated per second: 2.32e+03. Head worker occupation: 1.4%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.564e+02  5.623e-01  y = (((x₁ + x₁) + x₁) * x₁)                   9           5.217e+02  1.857e-01  y = (((x₁ * 1.5734) - 1.5179) * (x₁ + x₁))    12          4.931e+02  1.880e-02  y = (((x₁ * ((x₁ + x₁) + x₁)) - cos(x₁)) - 18.609)                                                                            13          4.783e+02  3.052e-02  y = ((((x₁ + (x₁ * 1.2976)) + -0.96141) + x₁) * (x₁ - 0.84207)...                                                                                               )                                             14          4.384e+02  8.695e-02  y = (((x₁ + x₁) * x₁) + ((x₁ * cos(0.67197 * x₁)) * x₁))                                                                      16          3.360e+02  1.331e-01  y = ((((x₁ - -1.769) + x₁) * x₁) + ((x₁ * cos(0.67197 * x₁)) *...                                                                                                x₁))                                         19          1.368e+02  2.994e-01  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "1.1%┣▌                                            ┫ 16/1.5k [00:02<02:55, 8it/s]Expressions evaluated per second: 2.32e+03. Head worker occupation: 1.4%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.564e+02  5.623e-01  y = (((x₁ + x₁) + x₁) * x₁)                   9           5.217e+02  1.857e-01  y = (((x₁ * 1.5734) - 1.5179) * (x₁ + x₁))    12          4.931e+02  1.880e-02  y = (((x₁ * ((x₁ + x₁) + x₁)) - cos(x₁)) - 18.609)                                                                            13          3.667e+02  2.961e-01  y = ((x₁ + ((x₁ + x₁) + x₁)) * (x₁ - (0.96611 + 0.96611)))                                                                    15          2.457e+02  2.002e-01  y = ((x₁ + ((x₁ + x₁) + x₁)) * (x₁ - ((0.96611 + 0.96611) * 1....                                                                                               3773)))                                       17          2.208e+02  5.338e-02  y = ((((x₁ + ((x₁ + x₁) + x₁)) * (x₁ - (0.96611 + 0.96611))) -...                                                                                                x₁) - x₁)                                    19          1.368e+02  2.393e-01  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "1.2%┣▌                                            ┫ 18/1.5k [00:02<02:42, 9it/s]Expressions evaluated per second: 2.32e+03. Head worker occupation: 1.3%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.564e+02  5.623e-01  y = (((x₁ + x₁) + x₁) * x₁)                   9           5.217e+02  1.857e-01  y = (((x₁ * 1.5734) - 1.5179) * (x₁ + x₁))    11          3.803e+02  1.580e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                13          2.666e+02  1.776e-01  y = ((((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁)) - x₁)                                                                         15          2.457e+02  4.080e-02  y = ((x₁ + ((x₁ + x₁) + x₁)) * (x₁ - ((0.96611 + 0.96611) * 1....                                                                                               3773)))                                       17          2.208e+02  5.338e-02  y = ((((x₁ + ((x₁ + x₁) + x₁)) * (x₁ - (0.96611 + 0.96611))) -...                                                                                                x₁) - x₁)                                    19          1.368e+02  2.393e-01  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "1.4%┣▋                                           ┫ 21/1.5k [00:02<02:25, 10it/s]Expressions evaluated per second: 2.32e+03. Head worker occupation: 1.4%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.564e+02  5.623e-01  y = (((x₁ + x₁) + x₁) * x₁)                   9           5.217e+02  1.857e-01  y = (((x₁ * 1.5734) - 1.5179) * (x₁ + x₁))    11          3.803e+02  1.580e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          2.666e+02  3.064e-01  y = ((((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁)) - x₁)                                                                         15          2.457e+02  4.080e-02  y = ((x₁ + ((x₁ + x₁) + x₁)) * (x₁ - ((0.96611 + 0.96611) * 1....                                                                                               3773)))                                       17          2.058e+02  8.858e-02  y = (((x₁ * (((x₁ + (x₁ * 3.1632)) + (x₁ + 0.84444)) - 21.194)...                                                                                               ) - x₁) + 9.4345)                             19          1.368e+02  2.041e-01  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "1.5%┣▊                                           ┫ 23/1.5k [00:02<02:24, 10it/s]Expressions evaluated per second: 2.32e+03. Head worker occupation: 1.2%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.564e+02  5.623e-01  y = (((x₁ + x₁) + x₁) * x₁)                   9           5.217e+02  1.857e-01  y = (((x₁ * 1.5734) - 1.5179) * (x₁ + x₁))    11          3.803e+02  1.580e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          2.666e+02  3.064e-01  y = ((((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁)) - x₁)                                                                         15          2.457e+02  4.080e-02  y = ((x₁ + ((x₁ + x₁) + x₁)) * (x₁ - ((0.96611 + 0.96611) * 1....                                                                                               3773)))                                       17          2.058e+02  8.858e-02  y = (((x₁ * (((x₁ + (x₁ * 3.1632)) + (x₁ + 0.84444)) - 21.194)...                                                                                               ) - x₁) + 9.4345)                             19          1.368e+02  2.041e-01  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "1.7%┣▊                                           ┫ 25/1.5k [00:02<02:18, 11it/s]Expressions evaluated per second: 3.25e+04. Head worker occupation: 1.2%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.564e+02  5.623e-01  y = (((x₁ + x₁) + x₁) * x₁)                   9           5.217e+02  1.857e-01  y = (((x₁ * 1.5734) - 1.5179) * (x₁ + x₁))    11          3.803e+02  1.580e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          2.666e+02  3.064e-01  y = ((((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁)) - x₁)                                                                         15          2.457e+02  4.080e-02  y = ((x₁ + ((x₁ + x₁) + x₁)) * (x₁ - ((0.96611 + 0.96611) * 1....                                                                                               3773)))                                       17          2.058e+02  8.858e-02  y = (((x₁ * (((x₁ + (x₁ * 3.1632)) + (x₁ + 0.84444)) - 21.194)...                                                                                               ) - x₁) + 9.4345)                             19          1.368e+02  2.041e-01  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "1.9%┣▉                                           ┫ 28/1.5k [00:02<02:10, 11it/s]Expressions evaluated per second: 3.25e+04. Head worker occupation: 1.2%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.442e+02  5.705e-01  y = (((1.9775 * x₁) + x₁) * x₁)               9           5.081e+02  1.908e-01  y = ((x₁ * ((x₁ + x₁) + x₁)) - 18.609)        10          5.031e+02  9.751e-03  y = (((1.7876 * x₁) + x₁) * (x₁ - cos(x₁)))   11          3.803e+02  2.798e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          2.666e+02  3.064e-01  y = ((((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁)) - x₁)                                                                         14          1.978e+02  2.985e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - cos(x₁)))                                                                 19          1.368e+02  7.369e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "2.1%┣█                                           ┫ 31/1.5k [00:02<02:02, 12it/s]Expressions evaluated per second: 3.25e+04. Head worker occupation: 1.2%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.442e+02  5.705e-01  y = (((1.9775 * x₁) + x₁) * x₁)               9           5.081e+02  1.908e-01  y = ((x₁ * ((x₁ + x₁) + x₁)) - 18.609)        10          5.031e+02  9.751e-03  y = (((1.7876 * x₁) + x₁) * (x₁ - cos(x₁)))   11          3.803e+02  2.798e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          2.666e+02  3.064e-01  y = ((((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁)) - x₁)                                                                         14          1.978e+02  2.985e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - cos(x₁)))                                                                 19          1.368e+02  7.369e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "2.3%┣█                                           ┫ 34/1.5k [00:03<01:57, 13it/s]Expressions evaluated per second: 3.25e+04. Head worker occupation: 1.2%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.707e+04  3.604e+01  y = x₁                                        3           8.230e+03  3.648e-01  y = (x₁ * x₁)                                 5           2.329e+03  6.312e-01  y = ((x₁ + x₁) * x₁)                          7           7.442e+02  5.705e-01  y = (((1.9775 * x₁) + x₁) * x₁)               9           5.081e+02  1.908e-01  y = ((x₁ * ((x₁ + x₁) + x₁)) - 18.609)        10          5.031e+02  9.751e-03  y = (((1.7876 * x₁) + x₁) * (x₁ - cos(x₁)))   11          3.803e+02  2.798e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          2.666e+02  3.064e-01  y = ((((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁)) - x₁)                                                                         14          1.978e+02  2.985e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - cos(x₁)))                                                                 19          1.368e+02  7.369e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "2.5%┣█                                           ┫ 37/1.5k [00:03<01:52, 13it/s]Expressions evaluated per second: 3.25e+04. Head worker occupation: 1.2%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.583e+04  3.604e+01  y = 17.479                                    3           3.750e+03  7.200e-01  y = (x₁ * 19.863)                             5           2.329e+03  2.382e-01  y = ((x₁ + x₁) * x₁)                          7           7.442e+02  5.705e-01  y = (((1.9775 * x₁) + x₁) * x₁)               9           5.081e+02  1.908e-01  y = ((x₁ * ((x₁ + x₁) + x₁)) - 18.609)        10          5.031e+02  9.751e-03  y = (((1.7876 * x₁) + x₁) * (x₁ - cos(x₁)))   11          3.803e+02  2.798e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          2.666e+02  3.064e-01  y = ((((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁)) - x₁)                                                                         14          1.978e+02  2.985e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - cos(x₁)))                                                                 19          1.368e+02  7.369e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "2.7%┣█▏                                          ┫ 40/1.5k [00:03<01:48, 13it/s]Expressions evaluated per second: 3.25e+04. Head worker occupation: 1.2%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.583e+04  3.604e+01  y = 17.479                                    3           3.750e+03  7.200e-01  y = (x₁ * 19.863)                             5           2.329e+03  2.382e-01  y = ((x₁ + x₁) * x₁)                          7           7.442e+02  5.705e-01  y = (((1.9775 * x₁) + x₁) * x₁)               9           5.081e+02  1.908e-01  y = ((x₁ * ((x₁ + x₁) + x₁)) - 18.609)        10          5.031e+02  9.751e-03  y = (((1.7876 * x₁) + x₁) * (x₁ - cos(x₁)))   11          3.803e+02  2.798e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          2.666e+02  3.064e-01  y = ((((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁)) - x₁)                                                                         14          1.978e+02  2.985e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - cos(x₁)))                                                                 19          1.368e+02  7.369e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "2.8%┣█▎                                          ┫ 42/1.5k [00:03<01:46, 14it/s]Expressions evaluated per second: 3.25e+04. Head worker occupation: 1.2%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.583e+04  3.604e+01  y = 17.479                                    3           3.750e+03  7.200e-01  y = (x₁ * 19.863)                             5           2.329e+03  2.382e-01  y = ((x₁ + x₁) * x₁)                          7           7.442e+02  5.705e-01  y = (((1.9775 * x₁) + x₁) * x₁)               9           5.081e+02  1.908e-01  y = ((x₁ * ((x₁ + x₁) + x₁)) - 18.609)        10          5.031e+02  9.751e-03  y = (((1.7876 * x₁) + x₁) * (x₁ - cos(x₁)))   11          3.803e+02  2.798e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          1.867e+02  6.629e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.866e+02  4.718e-05  y = ((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) + -0.086527) * (x...                                                                                               ₁ - -0.37935))                                19          1.368e+02  7.759e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "3.0%┣█▎                                          ┫ 45/1.5k [00:03<01:43, 14it/s]Expressions evaluated per second: 3.25e+04. Head worker occupation: 1.2%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.583e+04  3.604e+01  y = 17.479                                    3           3.750e+03  7.200e-01  y = (x₁ * 19.863)                             5           2.329e+03  2.382e-01  y = ((x₁ + x₁) * x₁)                          7           7.442e+02  5.705e-01  y = (((1.9775 * x₁) + x₁) * x₁)               9           5.081e+02  1.908e-01  y = ((x₁ * ((x₁ + x₁) + x₁)) - 18.609)        10          5.031e+02  9.751e-03  y = (((1.7876 * x₁) + x₁) * (x₁ - cos(x₁)))   11          3.803e+02  2.798e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          1.867e+02  6.629e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.866e+02  4.718e-05  y = ((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) + -0.086527) * (x...                                                                                               ₁ - -0.37935))                                19          1.368e+02  7.759e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "3.2%┣█▍                                          ┫ 48/1.5k [00:03<01:40, 15it/s]Expressions evaluated per second: 3.25e+04. Head worker occupation: 1.2%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.583e+04  3.604e+01  y = 17.479                                    3           3.750e+03  7.200e-01  y = (x₁ * 19.863)                             5           2.329e+03  2.382e-01  y = ((x₁ + x₁) * x₁)                          7           7.442e+02  5.705e-01  y = (((1.9775 * x₁) + x₁) * x₁)               9           5.081e+02  1.908e-01  y = ((x₁ * ((x₁ + x₁) + x₁)) - 18.609)        10          5.031e+02  9.751e-03  y = (((1.7876 * x₁) + x₁) * (x₁ - cos(x₁)))   11          3.803e+02  2.798e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          1.867e+02  6.629e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.866e+02  4.718e-05  y = ((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) + -0.086527) * (x...                                                                                               ₁ - -0.37935))                                19          1.368e+02  7.759e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "3.4%┣█▌                                          ┫ 51/1.5k [00:03<01:38, 15it/s]Expressions evaluated per second: 4.22e+04. Head worker occupation: 1.2%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.583e+04  3.604e+01  y = 17.479                                    3           3.750e+03  7.200e-01  y = (x₁ * 19.863)                             5           2.329e+03  2.382e-01  y = ((x₁ + x₁) * x₁)                          7           7.442e+02  5.705e-01  y = (((1.9775 * x₁) + x₁) * x₁)               9           5.081e+02  1.908e-01  y = ((x₁ * ((x₁ + x₁) + x₁)) - 18.609)        10          5.031e+02  9.751e-03  y = (((1.7876 * x₁) + x₁) * (x₁ - cos(x₁)))   11          3.803e+02  2.798e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          1.867e+02  6.629e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.866e+02  4.718e-05  y = ((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) + -0.086527) * (x...                                                                                               ₁ - -0.37935))                                19          1.368e+02  7.759e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "3.5%┣█▌                                          ┫ 53/1.5k [00:04<01:39, 15it/s]Expressions evaluated per second: 4.22e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.583e+04  3.604e+01  y = 17.479                                    3           3.750e+03  7.200e-01  y = (x₁ * 19.863)                             5           2.329e+03  2.382e-01  y = ((x₁ + x₁) * x₁)                          7           7.442e+02  5.705e-01  y = (((1.9775 * x₁) + x₁) * x₁)               9           5.081e+02  1.908e-01  y = ((x₁ * ((x₁ + x₁) + x₁)) - 18.609)        10          5.031e+02  9.751e-03  y = (((1.7876 * x₁) + x₁) * (x₁ - cos(x₁)))   11          3.803e+02  2.798e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          1.867e+02  6.629e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.866e+02  4.718e-05  y = ((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) + -0.086527) * (x...                                                                                               ₁ - -0.37935))                                19          1.368e+02  7.759e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "3.7%┣█▋                                          ┫ 56/1.5k [00:04<01:38, 15it/s]Expressions evaluated per second: 4.22e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           2.329e+03  2.382e-01  y = ((x₁ + x₁) * x₁)                          7           7.442e+02  5.705e-01  y = (((1.9775 * x₁) + x₁) * x₁)               9           5.020e+02  1.969e-01  y = ((((x₁ + x₁) + x₁) * x₁) + -16.893)       11          3.803e+02  1.387e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          1.867e+02  6.629e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.866e+02  4.718e-05  y = ((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) + -0.086527) * (x...                                                                                               ₁ - -0.37935))                                19          1.368e+02  7.759e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "3.9%┣█▊                                          ┫ 59/1.5k [00:04<01:36, 15it/s]Expressions evaluated per second: 4.22e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           2.329e+03  2.382e-01  y = ((x₁ + x₁) * x₁)                          7           7.316e+02  5.790e-01  y = ((x₁ + (x₁ * 1.9485)) * x₁)               9           5.020e+02  1.884e-01  y = ((((x₁ + x₁) + x₁) * x₁) + -16.893)       11          3.803e+02  1.387e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          1.867e+02  6.629e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.866e+02  4.718e-05  y = ((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) + -0.086527) * (x...                                                                                               ₁ - -0.37935))                                19          1.368e+02  7.759e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "4.1%┣█▉                                          ┫ 62/1.5k [00:04<01:34, 15it/s]Expressions evaluated per second: 4.22e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           2.329e+03  2.382e-01  y = ((x₁ + x₁) * x₁)                          7           7.251e+02  5.834e-01  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           5.020e+02  1.839e-01  y = ((((x₁ + x₁) + x₁) * x₁) + -16.893)       11          3.803e+02  1.387e-01  y = (((x₁ + (x₁ + x₁)) + x₁) * (-1.9087 + x₁))                                                                                12          3.622e+02  4.889e-02  y = (((x₁ - 2.2856) + (x₁ + x₁)) * (x₁ - cos(x₁)))                                                                            13          1.867e+02  6.629e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.866e+02  4.718e-05  y = ((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) + -0.086527) * (x...                                                                                               ₁ - -0.37935))                                19          1.368e+02  7.759e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "4.3%┣██                                          ┫ 65/1.5k [00:04<01:33, 15it/s]Expressions evaluated per second: 4.22e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           1.417e+03  4.866e-01  y = ((2.2941 * x₁) * x₁)                      7           7.251e+02  3.350e-01  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           5.020e+02  1.839e-01  y = ((((x₁ + x₁) + x₁) * x₁) + -16.893)       11          1.991e+02  4.625e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * x₁)                                                                             13          1.867e+02  3.216e-02  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.751e+02  3.188e-02  y = (((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * x₁) + x₁) + 0....                                                                                               45913)                                        16          1.742e+02  5.435e-03  y = ((((2.2941 * x₁) - -1.7473) + (x₁ - (12.888 - (x₁ - cos(-0...                                                                                               .58857))))) * x₁)                             17          1.626e+02  6.871e-02  y = (((((4.0741 * x₁) + ((x₁ - (18.018 - -3.418)) + -1.4188)) ...                                                                                               * x₁) + 22.877) + x₁)                         19          1.368e+02  8.627e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "4.5%┣██                                          ┫ 68/1.5k [00:04<01:31, 16it/s]Expressions evaluated per second: 4.22e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           1.417e+03  4.866e-01  y = ((2.2941 * x₁) * x₁)                      7           7.251e+02  3.350e-01  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           5.020e+02  1.839e-01  y = ((((x₁ + x₁) + x₁) * x₁) + -16.893)       11          1.991e+02  4.625e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * x₁)                                                                             13          1.867e+02  3.216e-02  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.751e+02  3.188e-02  y = (((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * x₁) + x₁) + 0....                                                                                               45913)                                        16          1.742e+02  5.435e-03  y = ((((2.2941 * x₁) - -1.7473) + (x₁ - (12.888 - (x₁ - cos(-0...                                                                                               .58857))))) * x₁)                             17          1.626e+02  6.871e-02  y = (((((4.0741 * x₁) + ((x₁ - (18.018 - -3.418)) + -1.4188)) ...                                                                                               * x₁) + 22.877) + x₁)                         19          1.368e+02  8.627e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - x₁) - (...                                                                                               -9.1109 - x₁)) + 9.4345)                      ---------------------------------------------------------------------------------------------------\n",
      "4.7%┣██                                          ┫ 70/1.5k [00:04<01:31, 16it/s]Expressions evaluated per second: 4.53e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           1.417e+03  4.866e-01  y = ((2.2941 * x₁) * x₁)                      7           7.251e+02  3.350e-01  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           5.020e+02  1.839e-01  y = ((((x₁ + x₁) + x₁) * x₁) + -16.893)       11          1.991e+02  4.625e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * x₁)                                                                             13          1.867e+02  3.216e-02  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.751e+02  3.188e-02  y = (((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * x₁) + x₁) + 0....                                                                                               45913)                                        16          1.742e+02  5.435e-03  y = ((((2.2941 * x₁) - -1.7473) + (x₁ - (12.888 - (x₁ - cos(-0...                                                                                               .58857))))) * x₁)                             17          1.626e+02  6.871e-02  y = (((((4.0741 * x₁) + ((x₁ - (18.018 - -3.418)) + -1.4188)) ...                                                                                               * x₁) + 22.877) + x₁)                         19          1.309e+02  1.083e-01  y = ((x₁ * (((x₁ + ((x₁ + -9.294) + x₁)) + x₁) + (x₁ + -9.294)...                                                                                               )) - (x₁ - 14.411))                           ---------------------------------------------------------------------------------------------------\n",
      "4.9%┣██▏                                         ┫ 73/1.5k [00:04<01:29, 16it/s]Expressions evaluated per second: 4.53e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           1.417e+03  4.866e-01  y = ((2.2941 * x₁) * x₁)                      7           7.251e+02  3.350e-01  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           5.020e+02  1.839e-01  y = ((((x₁ + x₁) + x₁) * x₁) + -16.893)       11          1.991e+02  4.625e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * x₁)                                                                             13          1.867e+02  3.216e-02  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.751e+02  3.188e-02  y = (((((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * x₁) + x₁) + 0....                                                                                               45913)                                        16          1.742e+02  5.435e-03  y = ((((2.2941 * x₁) - -1.7473) + (x₁ - (12.888 - (x₁ - cos(-0...                                                                                               .58857))))) * x₁)                             17          1.626e+02  6.871e-02  y = (((((4.0741 * x₁) + ((x₁ - (18.018 - -3.418)) + -1.4188)) ...                                                                                               * x₁) + 22.877) + x₁)                         19          1.309e+02  1.083e-01  y = ((x₁ * (((x₁ + ((x₁ + -9.294) + x₁)) + x₁) + (x₁ + -9.294)...                                                                                               )) - (x₁ - 14.411))                           ---------------------------------------------------------------------------------------------------\n",
      "5.1%┣██▎                                         ┫ 76/1.5k [00:05<01:28, 16it/s]Expressions evaluated per second: 4.53e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           1.417e+03  4.866e-01  y = ((2.2941 * x₁) * x₁)                      7           7.251e+02  3.350e-01  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           5.020e+02  1.839e-01  y = ((((x₁ + x₁) + x₁) * x₁) + -16.893)       11          1.991e+02  4.625e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * x₁)                                                                             13          1.867e+02  3.216e-02  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.422e+02  1.362e-01  y = ((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - (21.194 - -0.55726))...                                                                                               ) + 21.194)                                   18          1.362e+02  1.433e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - cos(x₁)...                                                                                               ) - -9.1109) + x₁)                            19          3.378e+01  1.394e+00  y = (x₁ * (((x₁ + ((x₁ * 0.18737) * x₁)) + x₁) - (((17.616 - 3...                                                                                               .3273) + -3.8295) - 4.2169)))                 ---------------------------------------------------------------------------------------------------\n",
      "5.3%┣██▎                                         ┫ 79/1.5k [00:05<01:26, 16it/s]Expressions evaluated per second: 4.53e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           1.417e+03  4.866e-01  y = ((2.2941 * x₁) * x₁)                      7           7.251e+02  3.350e-01  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           5.020e+02  1.839e-01  y = ((((x₁ + x₁) + x₁) * x₁) + -16.893)       11          1.991e+02  4.625e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * x₁)                                                                             13          1.867e+02  3.216e-02  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * (x₁ - -0.37935))                                                                15          1.422e+02  1.362e-01  y = ((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - (21.194 - -0.55726))...                                                                                               ) + 21.194)                                   18          1.362e+02  1.433e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - cos(x₁)...                                                                                               ) - -9.1109) + x₁)                            19          3.378e+01  1.394e+00  y = (x₁ * (((x₁ + ((x₁ * 0.18737) * x₁)) + x₁) - (((17.616 - 3...                                                                                               .3273) + -3.8295) - 4.2169)))                 ---------------------------------------------------------------------------------------------------\n",
      "5.5%┣██▍                                         ┫ 82/1.5k [00:05<01:25, 17it/s]Expressions evaluated per second: 4.53e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           1.417e+03  4.866e-01  y = ((2.2941 * x₁) * x₁)                      7           7.251e+02  3.350e-01  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           5.020e+02  1.839e-01  y = ((((x₁ + x₁) + x₁) * x₁) + -16.893)       11          1.991e+02  4.625e-01  y = (((2.2941 * x₁) + (x₁ - (12.888 - x₁))) * x₁)                                                                             13          1.741e+02  6.689e-02  y = (((2.2941 * x₁) + ((x₁ + 0.80345) - (12.888 - x₁))) * x₁)                                                                 15          1.422e+02  1.014e-01  y = ((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - (21.194 - -0.55726))...                                                                                               ) + 21.194)                                   18          1.362e+02  1.433e-02  y = ((((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - 21.194)) - cos(x₁)...                                                                                               ) - -9.1109) + x₁)                            19          3.378e+01  1.394e+00  y = (x₁ * (((x₁ + ((x₁ * 0.18737) * x₁)) + x₁) - (((17.616 - 3...                                                                                               .3273) + -3.8295) - 4.2169)))                 ---------------------------------------------------------------------------------------------------\n",
      "5.7%┣██▌                                         ┫ 85/1.5k [00:05<01:25, 17it/s]Expressions evaluated per second: 4.53e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           1.417e+03  4.866e-01  y = ((2.2941 * x₁) * x₁)                      7           7.251e+02  3.350e-01  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           1.904e+02  6.687e-01  y = (((4.0741 * x₁) + (x₁ - 18.018)) * x₁)    12          1.799e+02  1.895e-02  y = ((((4.0741 * x₁) + (x₁ - 18.018)) * x₁) - cos(x₁))                                                                        13          1.618e+02  1.060e-01  y = ((((1.793 * (x₁ + x₁)) + (x₁ - 17.306)) - -3.4429) * x₁)                                                                  15          1.422e+02  6.461e-02  y = ((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - (21.194 - -0.55726))...                                                                                               ) + 21.194)                                   17          9.616e-01  2.498e+00  y = ((((((-0.65969 * x₁) + (x₁ - -1.1142)) - 2.1686) * x₁) * x...                                                                                               ₁) + (x₁ * x₁))                               ---------------------------------------------------------------------------------------------------\n",
      "5.9%┣██▋                                         ┫ 88/1.5k [00:05<01:24, 17it/s]Expressions evaluated per second: 4.53e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           1.417e+03  4.866e-01  y = ((2.2941 * x₁) * x₁)                      7           7.251e+02  3.350e-01  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           1.904e+02  6.687e-01  y = (((4.0741 * x₁) + (x₁ - 18.018)) * x₁)    12          1.799e+02  1.895e-02  y = ((((4.0741 * x₁) + (x₁ - 18.018)) * x₁) - cos(x₁))                                                                        13          1.618e+02  1.060e-01  y = ((((1.793 * (x₁ + x₁)) + (x₁ - 17.306)) - -3.4429) * x₁)                                                                  15          1.422e+02  6.461e-02  y = ((x₁ * (((x₁ + (x₁ * 3.1632)) + x₁) - (21.194 - -0.55726))...                                                                                               ) + 21.194)                                   17          9.616e-01  2.498e+00  y = ((((((-0.65969 * x₁) + (x₁ - -1.1142)) - 2.1686) * x₁) * x...                                                                                               ₁) + (x₁ * x₁))                               ---------------------------------------------------------------------------------------------------\n",
      "6.1%┣██▊                                         ┫ 91/1.5k [00:05<01:23, 17it/s]Expressions evaluated per second: 4.53e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           7.251e+02  9.302e-02  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           1.904e+02  6.687e-01  y = (((4.0741 * x₁) + (x₁ - 18.018)) * x₁)    12          1.799e+02  1.895e-02  y = ((((4.0741 * x₁) + (x₁ - 18.018)) * x₁) - cos(x₁))                                                                        13          1.618e+02  1.060e-01  y = ((((1.793 * (x₁ + x₁)) + (x₁ - 17.306)) - -3.4429) * x₁)                                                                  14          3.593e+01  1.505e+00  y = (((((x₁ * x₁) + x₁) * (x₁ * 0.29154)) + cos(x₁)) + x₁)                                                                    17          9.616e-01  1.207e+00  y = ((((((-0.65969 * x₁) + (x₁ - -1.1142)) - 2.1686) * x₁) * x...                                                                                               ₁) + (x₁ * x₁))                               ---------------------------------------------------------------------------------------------------\n",
      "6.2%┣██▊                                         ┫ 93/1.5k [00:05<01:23, 17it/s]Expressions evaluated per second: 4.85e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           7.251e+02  9.302e-02  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           1.904e+02  6.687e-01  y = (((4.0741 * x₁) + (x₁ - 18.018)) * x₁)    12          1.799e+02  1.895e-02  y = ((((4.0741 * x₁) + (x₁ - 18.018)) * x₁) - cos(x₁))                                                                        13          1.618e+02  1.060e-01  y = ((((1.793 * (x₁ + x₁)) + (x₁ - 17.306)) - -3.4429) * x₁)                                                                  14          3.593e+01  1.505e+00  y = (((((x₁ * x₁) + x₁) * (x₁ * 0.29154)) + cos(x₁)) + x₁)                                                                    17          9.616e-01  1.207e+00  y = ((((((-0.65969 * x₁) + (x₁ - -1.1142)) - 2.1686) * x₁) * x...                                                                                               ₁) + (x₁ * x₁))                               ---------------------------------------------------------------------------------------------------\n",
      "6.4%┣██▉                                         ┫ 96/1.5k [00:06<01:22, 17it/s]Expressions evaluated per second: 4.85e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.151e+04  3.604e+01  y = 73.693                                    3           3.750e+03  5.606e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           7.251e+02  9.302e-02  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           1.904e+02  6.687e-01  y = (((4.0741 * x₁) + (x₁ - 18.018)) * x₁)    12          1.799e+02  1.895e-02  y = ((((4.0741 * x₁) + (x₁ - 18.018)) * x₁) - cos(x₁))                                                                        13          9.423e-01  5.252e+00  y = ((((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + x₁) - x₁)                                                                  ---------------------------------------------------------------------------------------------------\n",
      "6.6%┣███                                         ┫ 99/1.5k [00:06<01:21, 17it/s]Expressions evaluated per second: 4.85e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.140e+04  3.604e+01  y = 84.416                                    3           3.750e+03  5.559e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           7.251e+02  9.302e-02  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           1.904e+02  6.687e-01  y = (((4.0741 * x₁) + (x₁ - 18.018)) * x₁)    11          1.573e+02  9.553e-02  y = (((x₁ * (2.4462 + 2.2014)) * x₁) - (x₁ * 14.557))                                                                         13          9.423e-01  2.559e+00  y = ((((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + x₁) - x₁)                                                                  ---------------------------------------------------------------------------------------------------\n",
      "6.7%┣███                                        ┫ 101/1.5k [00:06<01:21, 17it/s]Expressions evaluated per second: 4.85e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.140e+04  3.604e+01  y = 84.416                                    3           3.750e+03  5.559e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           7.251e+02  9.302e-02  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           1.904e+02  6.687e-01  y = (((4.0741 * x₁) + (x₁ - 18.018)) * x₁)    11          1.573e+02  9.553e-02  y = (((x₁ * (2.4462 + 2.2014)) * x₁) - (x₁ * 14.557))                                                                         13          9.423e-01  2.559e+00  y = ((((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + x₁) - x₁)                                                                  ---------------------------------------------------------------------------------------------------\n",
      "6.9%┣███                                        ┫ 103/1.5k [00:06<01:21, 17it/s]Expressions evaluated per second: 4.85e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.140e+04  3.604e+01  y = 84.416                                    3           3.750e+03  5.559e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           7.251e+02  9.302e-02  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           1.904e+02  6.687e-01  y = (((4.0741 * x₁) + (x₁ - 18.018)) * x₁)    11          1.573e+02  9.553e-02  y = (((x₁ * (2.4462 + 2.2014)) * x₁) - (x₁ * 14.557))                                                                         13          9.423e-01  2.559e+00  y = ((((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + x₁) - x₁)                                                                  ---------------------------------------------------------------------------------------------------\n",
      "7.1%┣███                                        ┫ 106/1.5k [00:06<01:20, 18it/s]Expressions evaluated per second: 4.85e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.140e+04  3.604e+01  y = 84.416                                    3           3.750e+03  5.559e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           7.251e+02  9.302e-02  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           1.904e+02  6.687e-01  y = (((4.0741 * x₁) + (x₁ - 18.018)) * x₁)    11          1.573e+02  9.553e-02  y = (((x₁ * (2.4462 + 2.2014)) * x₁) - (x₁ * 14.557))                                                                         13          9.423e-01  2.559e+00  y = ((((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + x₁) - x₁)                                                                  ---------------------------------------------------------------------------------------------------\n",
      "7.3%┣███▏                                       ┫ 109/1.5k [00:06<01:19, 18it/s]Expressions evaluated per second: 4.85e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.140e+04  3.604e+01  y = 84.416                                    3           3.750e+03  5.559e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           7.251e+02  9.302e-02  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           1.904e+02  6.687e-01  y = (((4.0741 * x₁) + (x₁ - 18.018)) * x₁)    11          1.573e+02  9.553e-02  y = (((x₁ * (2.4462 + 2.2014)) * x₁) - (x₁ * 14.557))                                                                         13          9.423e-01  2.559e+00  y = ((((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + x₁) - x₁)                                                                  ---------------------------------------------------------------------------------------------------\n",
      "7.4%┣███▏                                       ┫ 111/1.5k [00:06<01:19, 18it/s]Expressions evaluated per second: 4.85e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.140e+04  3.604e+01  y = 84.416                                    3           3.750e+03  5.559e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           7.251e+02  9.302e-02  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           9.423e-01  3.323e+00  y = ((((-0.051382 * -6.5009) * x₁) * x₁) * x₁)                                                                                11          9.257e-01  8.900e-03  y = (((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + -0.16219)                                                                   ---------------------------------------------------------------------------------------------------\n",
      "7.6%┣███▎                                       ┫ 114/1.5k [00:06<01:18, 18it/s]Expressions evaluated per second: 5.04e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.140e+04  3.604e+01  y = 84.416                                    3           3.750e+03  5.559e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           7.251e+02  9.302e-02  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           9.423e-01  3.323e+00  y = ((((-0.051382 * -6.5009) * x₁) * x₁) * x₁)                                                                                11          9.257e-01  8.900e-03  y = (((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + -0.16219)                                                                   ---------------------------------------------------------------------------------------------------\n",
      "7.7%┣███▎                                       ┫ 116/1.5k [00:07<01:19, 18it/s]Expressions evaluated per second: 5.04e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.140e+04  3.604e+01  y = 84.416                                    3           3.750e+03  5.559e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           7.251e+02  9.302e-02  y = ((x₁ + x₁) * (x₁ * 1.4642))               9           9.423e-01  3.323e+00  y = ((((-0.051382 * -6.5009) * x₁) * x₁) * x₁)                                                                                11          9.257e-01  8.900e-03  y = (((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + -0.16219)                                                                   ---------------------------------------------------------------------------------------------------\n",
      "7.9%┣███▍                                       ┫ 119/1.5k [00:07<01:18, 18it/s]Expressions evaluated per second: 5.04e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.140e+04  3.604e+01  y = 84.416                                    3           3.750e+03  5.559e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           9.439e-01  3.415e+00  y = (x₁ * ((x₁ * x₁) * 0.33407))              9           9.423e-01  8.167e-04  y = ((((-0.051382 * -6.5009) * x₁) * x₁) * x₁)                                                                                11          9.257e-01  8.900e-03  y = (((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + -0.16219)                                                                   ---------------------------------------------------------------------------------------------------\n",
      "8.1%┣███▌                                       ┫ 122/1.5k [00:07<01:17, 18it/s]Expressions evaluated per second: 5.04e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.140e+04  3.604e+01  y = 84.416                                    3           3.750e+03  5.559e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           9.439e-01  3.415e+00  y = (x₁ * ((x₁ * x₁) * 0.33407))              9           9.423e-01  8.167e-04  y = ((((-0.051382 * -6.5009) * x₁) * x₁) * x₁)                                                                                11          9.257e-01  8.900e-03  y = (((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + -0.16219)                                                                   ---------------------------------------------------------------------------------------------------\n",
      "8.3%┣███▋                                       ┫ 125/1.5k [00:07<01:17, 18it/s]Expressions evaluated per second: 5.04e+04. Head worker occupation: 1.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.140e+04  3.604e+01  y = 84.416                                    3           3.750e+03  5.559e-01  y = (x₁ * 19.863)                             5           8.734e+02  7.286e-01  y = (x₁ * (x₁ * 2.5936))                      7           9.439e-01  3.415e+00  y = (x₁ * ((x₁ * x₁) * 0.33407))              9           9.423e-01  8.167e-04  y = ((((-0.051382 * -6.5009) * x₁) * x₁) * x₁)                                                                                11          9.257e-01  8.900e-03  y = (((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) + -0.16219)                                                                   15          4.007e-01  2.094e-01  y = ((((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) - cos(-0.6941...                                                                                               6)) - cos(x₁))                                16          8.124e-02  1.596e+00  y = (((((((-0.051382 * -6.5009) * x₁) * x₁) * x₁) - cos(x₁)) -...                                                                                                x₁) + x₁)                                    18          1.198e-24  1.802e+01  y = (((((((-0.10535 * -3.1641) * x₁) * x₁) * x₁) - cos(0.16561...                                                                                               )) - cos(x₁)) + cos(-0.16561))                ---------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "trained Machine; caches model-specific representations of data\n",
       "  model: SRRegressor(binary_operators = Function[+, -, *], …)\n",
       "  args: \n",
       "    1:\tSource @058 ⏎ AbstractMatrix{Continuous}\n",
       "    2:\tSource @330 ⏎ AbstractVector{Continuous}\n",
       "    3:\tSource @179 ⏎ Table{AbstractVector{Continuous}}\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SRRegressor(;\n",
    "    binary_operators=[+, -, *],\n",
    "    unary_operators=[cos],\n",
    "    loss_function=derivative_loss,\n",
    "    enable_autodiff=true,\n",
    "    batching=true,\n",
    "    batch_size=25,\n",
    "    niterations=100,\n",
    "    early_stop_condition=1e-6,\n",
    ")\n",
    "mach = machine(model, X, y, (; ∂y=∂y))\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8235ac-9c4d-4fc1-b478-c9492cc1d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the eta data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bb304dc-e02d-4da3-b569-90c701a2596e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 6), (1000,), (1000, 6))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in numpy data\n",
    "\n",
    "skip = 10\n",
    "\n",
    "jacobian = npzread(\"mean_jacobian_for_sr.npy\")\n",
    "\n",
    "X = npzread(\"toy_data_for_sr.npy\")[1:skip:10000, 1:6]\n",
    "\n",
    "#y = npzread(\"theta_eta_for_sr_model_0.npy\")[1:skip:10000, 7]\n",
    "\n",
    "\n",
    "#∂y = jacobian[1:skip:10000, 1, :] # learn the first element of the jacobian row \n",
    "# this will be the integral wrt A\n",
    "\n",
    "#size(X), size(y), size(∂y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44175913-eb6f-45f6-abba-afffc2b2eaa9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc SymbolicRegression.SRRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{AbstractMatrix{Continuous}, AbstractVector{Continuous}, Unknown}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Union{Tuple{Union{Table{<:AbstractVector{<:Continuous}}, AbstractMatrix{<:Continuous}}, AbstractVector{<:Continuous}}, Tuple{Union{Table{<:AbstractVector{<:Continuous}}, AbstractMatrix{<:Continuous}}, AbstractVector{<:Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/ByFwA/src/machines.jl:230\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(SRRegressor(binary_operators = Function[+, *, ^], …), …).\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mYou are using an experimental interface for the `extra` field of a `Dataset` type. This API may change in the future.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SymbolicRegression.MLJInterfaceModule ~/.julia/packages/SymbolicRegression/fHd3u/src/MLJInterface.jl:208\u001b[39m\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mYou are using multithreading mode, but only one thread is available. Try starting julia with `--threads=auto`.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ SymbolicRegression ~/.julia/packages/SymbolicRegression/fHd3u/src/SymbolicRegression.jl:553\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.0%┣                                           ┫ 0/1.5k [00:01<-18:-57, -1s/it]Expressions evaluated per second: [.....]. Head worker occupation: 0.0%         Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.600e+04  1.594e+01  y = x₁                                        3           5.881e+03  5.004e-01  y = (-12.901 * -8.3245)                       ---------------------------------------------------------------------------------------------------\n",
      "0.1%┣                                           ┫ 2/1.5k [00:03<01:03:09, 3s/it]Expressions evaluated per second: 4.29e+02. Head worker occupation: 0.0%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.598e+04  1.594e+01  y = x₃                                        3           5.388e+03  5.437e-01  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "0.3%┣▏                                             ┫ 4/1.5k [00:07<56:13, 2s/it]Expressions evaluated per second: 3.33e+02. Head worker occupation: 0.0%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.598e+04  1.594e+01  y = x₃                                        3           5.388e+03  5.437e-01  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "0.4%┣▏                                             ┫ 6/1.5k [00:10<51:08, 2s/it]Expressions evaluated per second: 3.28e+02. Head worker occupation: 0.0%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.598e+04  1.594e+01  y = x₃                                        3           5.388e+03  5.437e-01  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "0.5%┣▎                                             ┫ 8/1.5k [00:14<51:13, 2s/it]Expressions evaluated per second: 3.11e+02. Head worker occupation: 0.0%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           1.598e+04  1.594e+01  y = x₃                                        3           5.388e+03  5.437e-01  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "0.7%┣▎                                            ┫ 10/1.5k [00:19<52:13, 2s/it]Expressions evaluated per second: 2.99e+02. Head worker occupation: 0.0%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           5.857e+03  1.594e+01  y = 100.81                                    3           5.388e+03  4.175e-02  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "0.8%┣▍                                            ┫ 12/1.5k [00:22<49:34, 2s/it]Expressions evaluated per second: 3.13e+02. Head worker occupation: 0.0%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           5.857e+03  1.594e+01  y = 100.81                                    3           5.388e+03  4.175e-02  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "0.9%┣▍                                            ┫ 14/1.5k [00:25<48:32, 2s/it]Expressions evaluated per second: 3.02e+02. Head worker occupation: 0.0%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           5.857e+03  1.594e+01  y = 100.81                                    3           5.388e+03  4.175e-02  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "\u001b[1A\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTerminated early due to NaN in gradient.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Optim ~/.julia/packages/Optim/Adqv3/src/multivariate/optimize/optimize.jl:98\u001b[39m\n",
      "\u001b[1A\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTerminated early due to NaN in gradient.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Optim ~/.julia/packages/Optim/Adqv3/src/multivariate/optimize/optimize.jl:98\u001b[39m\n",
      "\u001b[1A\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTerminated early due to NaN in gradient.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Optim ~/.julia/packages/Optim/Adqv3/src/multivariate/optimize/optimize.jl:98\u001b[39m\n",
      "1.1%┣▌                                            ┫ 16/1.5k [00:30<49:03, 2s/it]Expressions evaluated per second: 3.00e+02. Head worker occupation: 0.0%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           5.857e+03  1.594e+01  y = 100.81                                    3           5.388e+03  4.175e-02  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTerminated early due to NaN in gradient.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Optim ~/.julia/packages/Optim/Adqv3/src/multivariate/optimize/optimize.jl:98\u001b[39m\n",
      "1.2%┣▌                                            ┫ 18/1.5k [00:32<46:07, 2s/it]Expressions evaluated per second: 3.40e+02. Head worker occupation: 0.0%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           5.857e+03  1.594e+01  y = 100.81                                    3           5.388e+03  4.175e-02  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTerminated early due to NaN in gradient.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Optim ~/.julia/packages/Optim/Adqv3/src/multivariate/optimize/optimize.jl:98\u001b[39m\n",
      "\u001b[1A\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mTerminated early due to NaN in gradient.\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Optim ~/.julia/packages/Optim/Adqv3/src/multivariate/optimize/optimize.jl:98\u001b[39m\n",
      "1.3%┣▋                                            ┫ 20/1.5k [00:37<47:24, 2s/it]Expressions evaluated per second: 3.63e+02. Head worker occupation: 0.0%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           5.857e+03  1.594e+01  y = 100.81                                    3           5.388e+03  4.175e-02  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "1.5%┣▋                                            ┫ 22/1.5k [00:44<51:37, 2s/it]Expressions evaluated per second: 3.47e+02. Head worker occupation: 0.0%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           5.857e+03  1.594e+01  y = 100.81                                    3           5.388e+03  4.175e-02  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "1.6%┣▊                                            ┫ 24/1.5k [00:49<51:56, 2s/it]Expressions evaluated per second: 3.35e+02. Head worker occupation: 0.1%        Press 'q' and then <enter> to stop execution early.                             Hall of Fame:                                                                   ---------------------------------------------------------------------------------------------------                                                             Complexity  Loss       Score     Equation                                       1           5.857e+03  1.594e+01  y = 100.81                                    3           5.388e+03  4.175e-02  y = (x₃ * 68.495)                             ---------------------------------------------------------------------------------------------------\n",
      "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mProblem fitting the machine machine(SRRegressor(binary_operators = Function[+, *, ^], …), …). \n",
      "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/ByFwA/src/machines.jl:682\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRunning type checks... \n",
      "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mThe number and/or types of data arguments do not match what the specified model\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msupports. Suppress this type check by specifying `scitype_check_level=0`.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mRun `@doc SymbolicRegression.SRRegressor` to learn more about your model's requirements.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mCommonly, but non exclusively, supervised models are constructed using the syntax\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m`machine(model, X, y)` or `machine(model, X, y, w)` while most other models are\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mconstructed with `machine(model, X)`.  Here `X` are features, `y` a target, and `w`\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39msample or class weights.\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn general, data in `machine(model, data...)` is expected to satisfy\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m    scitype(data) <: MLJ.fit_data_scitype(model)\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mIn the present case:\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mscitype(data) = Tuple{AbstractMatrix{Continuous}, AbstractVector{Continuous}, Unknown}\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m\n",
      "\u001b[33m\u001b[1m│ \u001b[22m\u001b[39mfit_data_scitype(model) = Union{Tuple{Union{Table{<:AbstractVector{<:Continuous}}, AbstractMatrix{<:Continuous}}, AbstractVector{<:Continuous}}, Tuple{Union{Table{<:AbstractVector{<:Continuous}}, AbstractMatrix{<:Continuous}}, AbstractVector{<:Continuous}, AbstractVector{<:Union{Continuous, Count}}}}\n",
      "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/ByFwA/src/machines.jl:230\u001b[39m\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mIt seems an upstream node in a learning network is providing data of incompatible scitype. See above. \n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "TaskFailedException\n\n\u001b[91m    nested task error: \u001b[39mTaskFailedException\n    Stacktrace:\n     [1] \u001b[0m\u001b[1mwait\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:345\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [2] \u001b[0m\u001b[1mfetch\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:360\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [3] \u001b[0m\u001b[1m(::SymbolicRegression.var\"#53#80\"{Vector{Vector{Channel{Any}}}, Vector{Vector{Task}}, Int64, Int64})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mSymbolicRegression\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:484\u001b[24m\u001b[39m\n    \n    \u001b[91m    nested task error: \u001b[39mInterruptException:\n        Stacktrace:\n          [1] \u001b[0m\u001b[1mPullback\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mOperators.jl:47\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n          [2] \u001b[0m\u001b[1m(::Zygote.Pullback{Tuple{typeof(safe_pow), Float32, Float32}, Any})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mΔ\u001b[39m::\u001b[0mFloat32\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[35mZygote\u001b[39m \u001b[90m~/.julia/packages/Zygote/4rucm/src/compiler/\u001b[39m\u001b[90m\u001b[4minterface2.jl:0\u001b[24m\u001b[39m\n          [3] \u001b[0m\u001b[1m(::Zygote.var\"#75#76\"{Zygote.Pullback{Tuple{typeof(safe_pow), Float32, Float32}, Any}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mΔ\u001b[39m::\u001b[0mFloat32\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[35mZygote\u001b[39m \u001b[90m~/.julia/packages/Zygote/4rucm/src/compiler/\u001b[39m\u001b[90m\u001b[4minterface.jl:45\u001b[24m\u001b[39m\n          [4] \u001b[0m\u001b[1mgradient\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mFunction, ::\u001b[0mFloat32, ::\u001b[0mVararg\u001b[90m{Float32}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[35mZygote\u001b[39m \u001b[90m~/.julia/packages/Zygote/4rucm/src/compiler/\u001b[39m\u001b[90m\u001b[4minterface.jl:97\u001b[24m\u001b[39m\n          [5] \u001b[0m\u001b[1m#3\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/DynamicExpressions/KRT17/ext_compat/\u001b[39m\u001b[90m\u001b[4mDynamicExpressionsZygoteExt.jl:14\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n          [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:373\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n          [7] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4msimdloop.jl:77\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n          [8] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mUtils.jl:54\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n          [9] \u001b[0m\u001b[1mgrad_deg2_eval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{6}\u001b[39m, \u001b[90mindex_tree\u001b[39m::\u001b[0mDynamicExpressions.EquationUtilsModule.NodeIndex, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90mop\u001b[39m::\u001b[0mtypeof(safe_pow), \u001b[90mdiff_op\u001b[39m::\u001b[0mDynamicExpressions.DynamicExpressionsZygoteExt.var\"#3#4\"\u001b[90m{typeof(safe_pow)}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{true}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{false}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:367\u001b[24m\u001b[39m\n         [10] \u001b[0m\u001b[1m_eval_grad_tree_array\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{6}\u001b[39m, \u001b[90mindex_tree\u001b[39m::\u001b[0mDynamicExpressions.EquationUtilsModule.NodeIndex, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{true}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{false}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:276\u001b[24m\u001b[39m\n         [11] \u001b[0m\u001b[1meval_grad_tree_array\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:226\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n         [12] \u001b[0m\u001b[1mgrad_deg2_eval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{6}\u001b[39m, \u001b[90mindex_tree\u001b[39m::\u001b[0mDynamicExpressions.EquationUtilsModule.NodeIndex, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90mop\u001b[39m::\u001b[0mtypeof(+), \u001b[90mdiff_op\u001b[39m::\u001b[0mDynamicExpressions.DynamicExpressionsZygoteExt.var\"#3#4\"\u001b[90m{typeof(+)}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{true}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{false}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:358\u001b[24m\u001b[39m\n         [13] \u001b[0m\u001b[1m_eval_grad_tree_array\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{6}\u001b[39m, \u001b[90mindex_tree\u001b[39m::\u001b[0mDynamicExpressions.EquationUtilsModule.NodeIndex, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{true}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{false}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:276\u001b[24m\u001b[39m\n         [14] \u001b[0m\u001b[1meval_grad_tree_array\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{6}\u001b[39m, \u001b[90mindex_tree\u001b[39m::\u001b[0mDynamicExpressions.EquationUtilsModule.NodeIndex, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{true}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{false}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:226\u001b[24m\u001b[39m\n         [15] \u001b[0m\u001b[1meval_grad_tree_array\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum; \u001b[90mvariable\u001b[39m::\u001b[0mBool, \u001b[90mturbo\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:204\u001b[24m\u001b[39m\n         [16] \u001b[0m\u001b[1m#eval_grad_tree_array#2\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mInterfaceDynamicExpressions.jl:112\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n         [17] \u001b[0m\u001b[1mderivative_loss\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90mdataset\u001b[39m::\u001b[0mDataset\u001b[90m{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}\u001b[39m, \u001b[90moptions\u001b[39m::\u001b[0mOptions\u001b[90m{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}\u001b[39m, \u001b[90midx\u001b[39m::\u001b[0mVector\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[32mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[5]:6\u001b[24m\u001b[39m\n         [18] \u001b[0m\u001b[1mevaluator\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mtypeof(derivative_loss), \u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90mdataset\u001b[39m::\u001b[0mDataset\u001b[90m{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}\u001b[39m, \u001b[90moptions\u001b[39m::\u001b[0mOptions\u001b[90m{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}\u001b[39m, \u001b[90midx\u001b[39m::\u001b[0mVector\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[33mSymbolicRegression.LossFunctionsModule\u001b[39m \u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mLossFunctions.jl:80\u001b[24m\u001b[39m\n         [19] \u001b[0m\u001b[1meval_loss\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90mdataset\u001b[39m::\u001b[0mDataset\u001b[90m{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}\u001b[39m, \u001b[90moptions\u001b[39m::\u001b[0mOptions\u001b[90m{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}\u001b[39m; \u001b[90mregularization\u001b[39m::\u001b[0mBool, \u001b[90midx\u001b[39m::\u001b[0mVector\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[33mSymbolicRegression.LossFunctionsModule\u001b[39m \u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mLossFunctions.jl:105\u001b[24m\u001b[39m\n         [20] \u001b[0m\u001b[1m#eval_loss_batched#4\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mLossFunctions.jl:119\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n         [21] \u001b[0m\u001b[1m#score_func_batched#6\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mLossFunctions.jl:181\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n         [22] \u001b[0m\u001b[1ms_r_cycle\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mdataset\u001b[39m::\u001b[0mDataset\u001b[90m{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}\u001b[39m, \u001b[90mpop\u001b[39m::\u001b[0mPopulation\u001b[90m{Float32, Float32}\u001b[39m, \u001b[90mncycles\u001b[39m::\u001b[0mInt64, \u001b[90mcurmaxsize\u001b[39m::\u001b[0mInt64, \u001b[90mrunning_search_statistics\u001b[39m::\u001b[0mSymbolicRegression.AdaptiveParsimonyModule.RunningSearchStatistics; \u001b[90mverbosity\u001b[39m::\u001b[0mInt64, \u001b[90moptions\u001b[39m::\u001b[0mOptions\u001b[90m{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}\u001b[39m, \u001b[90mrecord\u001b[39m::\u001b[0mDict\u001b[90m{String, Any}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[33mSymbolicRegression.SingleIterationModule\u001b[39m \u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mSingleIteration.jl:62\u001b[24m\u001b[39m\n         [23] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mSymbolicRegression.jl:955\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n         [24] \u001b[0m\u001b[1m(::SymbolicRegression.var\"#52#79\"{Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}, Int64, Population{Float32, Float32}, SymbolicRegression.AdaptiveParsimonyModule.RunningSearchStatistics, Int64, Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[33mSymbolicRegression\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mthreadingconstructs.jl:258\u001b[24m\u001b[39m",
     "output_type": "error",
     "traceback": [
      "TaskFailedException\n\n\u001b[91m    nested task error: \u001b[39mTaskFailedException\n    Stacktrace:\n     [1] \u001b[0m\u001b[1mwait\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:345\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [2] \u001b[0m\u001b[1mfetch\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:360\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n     [3] \u001b[0m\u001b[1m(::SymbolicRegression.var\"#53#80\"{Vector{Vector{Channel{Any}}}, Vector{Vector{Task}}, Int64, Int64})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mSymbolicRegression\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mtask.jl:484\u001b[24m\u001b[39m\n    \n    \u001b[91m    nested task error: \u001b[39mInterruptException:\n        Stacktrace:\n          [1] \u001b[0m\u001b[1mPullback\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mOperators.jl:47\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n          [2] \u001b[0m\u001b[1m(::Zygote.Pullback{Tuple{typeof(safe_pow), Float32, Float32}, Any})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mΔ\u001b[39m::\u001b[0mFloat32\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[35mZygote\u001b[39m \u001b[90m~/.julia/packages/Zygote/4rucm/src/compiler/\u001b[39m\u001b[90m\u001b[4minterface2.jl:0\u001b[24m\u001b[39m\n          [3] \u001b[0m\u001b[1m(::Zygote.var\"#75#76\"{Zygote.Pullback{Tuple{typeof(safe_pow), Float32, Float32}, Any}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mΔ\u001b[39m::\u001b[0mFloat32\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[35mZygote\u001b[39m \u001b[90m~/.julia/packages/Zygote/4rucm/src/compiler/\u001b[39m\u001b[90m\u001b[4minterface.jl:45\u001b[24m\u001b[39m\n          [4] \u001b[0m\u001b[1mgradient\u001b[22m\u001b[0m\u001b[1m(\u001b[22m::\u001b[0mFunction, ::\u001b[0mFloat32, ::\u001b[0mVararg\u001b[90m{Float32}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[35mZygote\u001b[39m \u001b[90m~/.julia/packages/Zygote/4rucm/src/compiler/\u001b[39m\u001b[90m\u001b[4minterface.jl:97\u001b[24m\u001b[39m\n          [5] \u001b[0m\u001b[1m#3\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/DynamicExpressions/KRT17/ext_compat/\u001b[39m\u001b[90m\u001b[4mDynamicExpressionsZygoteExt.jl:14\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n          [6] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:373\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n          [7] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90m\u001b[4msimdloop.jl:77\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n          [8] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mUtils.jl:54\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n          [9] \u001b[0m\u001b[1mgrad_deg2_eval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{6}\u001b[39m, \u001b[90mindex_tree\u001b[39m::\u001b[0mDynamicExpressions.EquationUtilsModule.NodeIndex, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90mop\u001b[39m::\u001b[0mtypeof(safe_pow), \u001b[90mdiff_op\u001b[39m::\u001b[0mDynamicExpressions.DynamicExpressionsZygoteExt.var\"#3#4\"\u001b[90m{typeof(safe_pow)}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{true}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{false}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:367\u001b[24m\u001b[39m\n         [10] \u001b[0m\u001b[1m_eval_grad_tree_array\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{6}\u001b[39m, \u001b[90mindex_tree\u001b[39m::\u001b[0mDynamicExpressions.EquationUtilsModule.NodeIndex, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{true}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{false}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:276\u001b[24m\u001b[39m\n         [11] \u001b[0m\u001b[1meval_grad_tree_array\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:226\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n         [12] \u001b[0m\u001b[1mgrad_deg2_eval\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{6}\u001b[39m, \u001b[90mindex_tree\u001b[39m::\u001b[0mDynamicExpressions.EquationUtilsModule.NodeIndex, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90mop\u001b[39m::\u001b[0mtypeof(+), \u001b[90mdiff_op\u001b[39m::\u001b[0mDynamicExpressions.DynamicExpressionsZygoteExt.var\"#3#4\"\u001b[90m{typeof(+)}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{true}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{false}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:358\u001b[24m\u001b[39m\n         [13] \u001b[0m\u001b[1m_eval_grad_tree_array\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{6}\u001b[39m, \u001b[90mindex_tree\u001b[39m::\u001b[0mDynamicExpressions.EquationUtilsModule.NodeIndex, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{true}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{false}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:276\u001b[24m\u001b[39m\n         [14] \u001b[0m\u001b[1meval_grad_tree_array\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{6}\u001b[39m, \u001b[90mindex_tree\u001b[39m::\u001b[0mDynamicExpressions.EquationUtilsModule.NodeIndex, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{true}\u001b[39m, \u001b[90m#unused#\u001b[39m::\u001b[0mVal\u001b[90m{false}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:226\u001b[24m\u001b[39m\n         [15] \u001b[0m\u001b[1meval_grad_tree_array\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90mcX\u001b[39m::\u001b[0mSubArray\u001b[90m{Float32, 2, Matrix{Float32}, Tuple{Base.Slice{Base.OneTo{Int64}}, Vector{Int64}}, false}\u001b[39m, \u001b[90moperators\u001b[39m::\u001b[0mDynamicExpressions.OperatorEnumModule.OperatorEnum; \u001b[90mvariable\u001b[39m::\u001b[0mBool, \u001b[90mturbo\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[36mDynamicExpressions.EvaluateEquationDerivativeModule\u001b[39m \u001b[90m~/.julia/packages/DynamicExpressions/KRT17/src/\u001b[39m\u001b[90m\u001b[4mEvaluateEquationDerivative.jl:204\u001b[24m\u001b[39m\n         [16] \u001b[0m\u001b[1m#eval_grad_tree_array#2\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mInterfaceDynamicExpressions.jl:112\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n         [17] \u001b[0m\u001b[1mderivative_loss\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90mdataset\u001b[39m::\u001b[0mDataset\u001b[90m{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}\u001b[39m, \u001b[90moptions\u001b[39m::\u001b[0mOptions\u001b[90m{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}\u001b[39m, \u001b[90midx\u001b[39m::\u001b[0mVector\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[32mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mIn[5]:6\u001b[24m\u001b[39m\n         [18] \u001b[0m\u001b[1mevaluator\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mf\u001b[39m::\u001b[0mtypeof(derivative_loss), \u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90mdataset\u001b[39m::\u001b[0mDataset\u001b[90m{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}\u001b[39m, \u001b[90moptions\u001b[39m::\u001b[0mOptions\u001b[90m{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}\u001b[39m, \u001b[90midx\u001b[39m::\u001b[0mVector\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[33mSymbolicRegression.LossFunctionsModule\u001b[39m \u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mLossFunctions.jl:80\u001b[24m\u001b[39m\n         [19] \u001b[0m\u001b[1meval_loss\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mtree\u001b[39m::\u001b[0mDynamicExpressions.EquationModule.Node\u001b[90m{Float32}\u001b[39m, \u001b[90mdataset\u001b[39m::\u001b[0mDataset\u001b[90m{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}\u001b[39m, \u001b[90moptions\u001b[39m::\u001b[0mOptions\u001b[90m{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}\u001b[39m; \u001b[90mregularization\u001b[39m::\u001b[0mBool, \u001b[90midx\u001b[39m::\u001b[0mVector\u001b[90m{Int64}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[33mSymbolicRegression.LossFunctionsModule\u001b[39m \u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mLossFunctions.jl:105\u001b[24m\u001b[39m\n         [20] \u001b[0m\u001b[1m#eval_loss_batched#4\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mLossFunctions.jl:119\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n         [21] \u001b[0m\u001b[1m#score_func_batched#6\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mLossFunctions.jl:181\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n         [22] \u001b[0m\u001b[1ms_r_cycle\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90mdataset\u001b[39m::\u001b[0mDataset\u001b[90m{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}\u001b[39m, \u001b[90mpop\u001b[39m::\u001b[0mPopulation\u001b[90m{Float32, Float32}\u001b[39m, \u001b[90mncycles\u001b[39m::\u001b[0mInt64, \u001b[90mcurmaxsize\u001b[39m::\u001b[0mInt64, \u001b[90mrunning_search_statistics\u001b[39m::\u001b[0mSymbolicRegression.AdaptiveParsimonyModule.RunningSearchStatistics; \u001b[90mverbosity\u001b[39m::\u001b[0mInt64, \u001b[90moptions\u001b[39m::\u001b[0mOptions\u001b[90m{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}\u001b[39m, \u001b[90mrecord\u001b[39m::\u001b[0mDict\u001b[90m{String, Any}\u001b[39m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[33mSymbolicRegression.SingleIterationModule\u001b[39m \u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mSingleIteration.jl:62\u001b[24m\u001b[39m\n         [23] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[90m~/.julia/packages/SymbolicRegression/fHd3u/src/\u001b[39m\u001b[90m\u001b[4mSymbolicRegression.jl:955\u001b[24m\u001b[39m\u001b[90m [inlined]\u001b[39m\n         [24] \u001b[0m\u001b[1m(::SymbolicRegression.var\"#52#79\"{Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}, Int64, Population{Float32, Float32}, SymbolicRegression.AdaptiveParsimonyModule.RunningSearchStatistics, Int64, Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n        \u001b[90m    @ \u001b[39m\u001b[33mSymbolicRegression\u001b[39m \u001b[90m./\u001b[39m\u001b[90m\u001b[4mthreadingconstructs.jl:258\u001b[24m\u001b[39m",
      "",
      "Stacktrace:",
      "  [1] wait",
      "    @ ./task.jl:345 [inlined]",
      "  [2] fetch",
      "    @ ./task.jl:360 [inlined]",
      "  [3] _equation_search(#unused#::Val{:multithreading}, #unused#::Val{1}, datasets::Vector{Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}}, niterations::Int64, options::Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}, numprocs::Nothing, procs::Nothing, addprocs_function::Nothing, runtests::Bool, saved_state::Nothing, verbosity::Int64, progress::Bool, #unused#::Val{true})",
      "    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/fHd3u/src/SymbolicRegression.jl:831",
      "  [4] equation_search(datasets::Vector{Dataset{Float32, Float32, Matrix{Float32}, Vector{Float32}, Nothing, NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, Nothing, Nothing, Nothing, Nothing}}; niterations::Int64, options::Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}, parallelism::Symbol, numprocs::Nothing, procs::Nothing, addprocs_function::Nothing, runtests::Bool, saved_state::Nothing, return_state::Bool, verbosity::Int64, progress::Nothing, v_dim_out::Val{1})",
      "    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/fHd3u/src/SymbolicRegression.jl:514",
      "  [5] equation_search(X::Matrix{Float32}, y::Matrix{Float32}; niterations::Int64, weights::Nothing, extra::NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, options::Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}}, variable_names::Vector{String}, display_variable_names::Vector{String}, y_variable_names::Nothing, parallelism::Symbol, numprocs::Nothing, procs::Nothing, addprocs_function::Nothing, runtests::Bool, saved_state::Nothing, return_state::Bool, loss_type::Type{Nothing}, verbosity::Int64, progress::Nothing, X_units::Nothing, y_units::Nothing, v_dim_out::Val{1}, multithreaded::Nothing, varMap::Nothing)",
      "    @ SymbolicRegression ~/.julia/packages/SymbolicRegression/fHd3u/src/SymbolicRegression.jl:392",
      "  [6] #equation_search#24",
      "    @ ~/.julia/packages/SymbolicRegression/fHd3u/src/SymbolicRegression.jl:421 [inlined]",
      "  [7] _update(m::SRRegressor{DynamicQuantities.SymbolicDimensions{DynamicQuantities.FixedRational{Int32, 25200}}, DataType, false}, verbosity::Int64, old_fitresult::Nothing, old_cache::Nothing, X::Matrix{Float32}, y::Vector{Float32}, w::NamedTuple{(:∂y,), Tuple{Matrix{Float32}}}, options::Options{Int64, DynamicExpressions.OperatorEnumModule.OperatorEnum, false, Optim.Options{Float64, Nothing}, StatsBase.Weights{Float64, Float64, Vector{Float64}}})",
      "    @ SymbolicRegression.MLJInterfaceModule ~/.julia/packages/SymbolicRegression/fHd3u/src/MLJInterface.jl:152",
      "  [8] update(m::SRRegressor{DynamicQuantities.SymbolicDimensions{DynamicQuantities.FixedRational{Int32, 25200}}, DataType, false}, verbosity::Int64, old_fitresult::Nothing, old_cache::Nothing, X::Matrix{Float32}, y::Vector{Float32}, w::NamedTuple{(:∂y,), Tuple{Matrix{Float32}}})",
      "    @ SymbolicRegression.MLJInterfaceModule ~/.julia/packages/SymbolicRegression/fHd3u/src/MLJInterface.jl:124",
      "  [9] fit(m::SRRegressor{DynamicQuantities.SymbolicDimensions{DynamicQuantities.FixedRational{Int32, 25200}}, DataType, false}, verbosity::Int64, X::Matrix{Float32}, y::Vector{Float32}, w::NamedTuple{(:∂y,), Tuple{Matrix{Float32}}})",
      "    @ SymbolicRegression.MLJInterfaceModule ~/.julia/packages/SymbolicRegression/fHd3u/src/MLJInterface.jl:118",
      " [10] fit_only!(mach::Machine{SRRegressor{DynamicQuantities.SymbolicDimensions{DynamicQuantities.FixedRational{Int32, 25200}}, DataType, false}, true}; rows::Nothing, verbosity::Int64, force::Bool, composite::Nothing)",
      "    @ MLJBase ~/.julia/packages/MLJBase/ByFwA/src/machines.jl:680",
      " [11] fit_only!",
      "    @ ~/.julia/packages/MLJBase/ByFwA/src/machines.jl:606 [inlined]",
      " [12] #fit!#63",
      "    @ ~/.julia/packages/MLJBase/ByFwA/src/machines.jl:778 [inlined]",
      " [13] fit!(mach::Machine{SRRegressor{DynamicQuantities.SymbolicDimensions{DynamicQuantities.FixedRational{Int32, 25200}}, DataType, false}, true})",
      "    @ MLJBase ~/.julia/packages/MLJBase/ByFwA/src/machines.jl:775",
      " [14] top-level scope",
      "    @ In[9]:17"
     ]
    }
   ],
   "source": [
    "model = SRRegressor(;\n",
    "    binary_operators=[+, *, ^],\n",
    "    unary_operators=[log],\n",
    "    constraints=[(^)=>(-1, 9)],\n",
    "    nested_constraints=[(^) => [(^) => 0, log => 0],\n",
    "                   log => [(^) =>  0, log => 0],\n",
    "            #        exp => [log => 0]\n",
    "        ],\n",
    "    loss_function=derivative_loss,\n",
    "    enable_autodiff=true,\n",
    "    batching=false,\n",
    "    #batch_size=100,\n",
    "    niterations=100,\n",
    "    parsimony=100,\n",
    ")\n",
    "mach = machine(model, X, y, (; ∂y=∂y))\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf72f2c-3b4b-47a7-8980-0aee00aee91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = report(mach)\n",
    "eq = r.equations[r.best_idx]\n",
    "\n",
    "variable_names = [\"A_\", \"B_\", \"C_\", \"D_\", \"E_\", \"F_\"]\n",
    "symbolic_eq = node_to_symbolic(eq, model, variable_names=variable_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59adb52e-aa79-4bd0-9925-dcce90f31615",
   "metadata": {},
   "source": [
    "## loss for fitting $y=\\partial y$\n",
    "here we want to pass the derivatives as an extra and fit the candidate expression to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff80e74-eb92-43f4-81cf-6474d9d5c783",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "old_derivative_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function old_derivative_loss(tree, dataset::Dataset{T,L}, options, idx) where {T,L}\n",
    "    # Column-major:\n",
    "    X = idx === nothing ? dataset.X : view(dataset.X, :, idx)\n",
    "    ∂y = idx === nothing ? dataset.y : view(dataset.y, idx)\n",
    "\n",
    "    ŷ, ∂ŷ, completed = eval_grad_tree_array(tree, X, options; variable=true)\n",
    "\n",
    "    !completed && return L(Inf)\n",
    "\n",
    "    mse = sum(i -> (∂ŷ[i] - ∂y[i])^2, eachindex(∂y)) / length(∂y)\n",
    "    return mse\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89ea2000-5252-487d-a2be-e4982d8e9533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fit_derivative_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fit_derivative_loss(tree, dataset::Dataset{T,L}, options, idx) where {T,L}\n",
    "    # Column-major:\n",
    "    X = idx === nothing ? dataset.X : view(dataset.X, :, idx)\n",
    "    #∂y = idx === nothing ? dataset.y : view(dataset.y, idx)\n",
    "\n",
    "    ŷ, ∂ŷ, completed = eval_grad_tree_array(tree, X, options; variable=true)\n",
    "\n",
    "    !completed && return L(Inf)\n",
    "\n",
    "    y = idx === nothing ? dataset.y : view(dataset.y, idx)\n",
    "    ∂y = idx === nothing ? dataset.extra.∂y : view(dataset.extra.∂y, idx)\n",
    "    \n",
    "    # match the derivative only\n",
    "    mse = sum(i -> (∂ŷ[i] - ∂y[i])^2, eachindex(∂y)) / length(∂y)\n",
    "    \n",
    "    return mse\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0778bec2-992d-4e1c-b122-ba2afd6684a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 6), (1000,), (1000, 6))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in numpy data\n",
    "\n",
    "skip = 10\n",
    "\n",
    "jacobian = npzread(\"mean_jacobian_for_sr.npy\")\n",
    "\n",
    "X = npzread(\"theta_eta_for_sr_model_0.npy\")[1:skip:10000, 1:6]\n",
    "\n",
    "y = npzread(\"theta_eta_for_sr_model_0.npy\")[1:skip:10000, 7]\n",
    "\n",
    "\n",
    "∂y = jacobian[1:skip:10000, 1, :] # learn the first element of the jacobian row \n",
    "# this will be the integral wrt A\n",
    "\n",
    "size(X), size(y), size(∂y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5d8049-cd80-4cba-ae7f-193cc1676ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRRegressor(;\n",
    "    binary_operators=[+, *, ^],\n",
    "    unary_operators=[log],\n",
    "    constraints=[(^)=>(-1, 9)],\n",
    "    nested_constraints=[(^) => [(^) => 0, log => 0],\n",
    "                   log => [(^) =>  0, log => 0],\n",
    "            #        exp => [log => 0]\n",
    "        ],\n",
    "    loss_function=fit_derivative_loss,\n",
    "    enable_autodiff=true,\n",
    "    batching=true,\n",
    "    batch_size=100,\n",
    "    niterations=100,\n",
    "    parsimony=100,\n",
    ")\n",
    "mach = machine(model, X, y, (; ∂y=∂y))\n",
    "fit!(mach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e26ad-c725-4a23-9f24-8f28ab7fa4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = report(mach)\n",
    "eq = r.equations[r.best_idx]\n",
    "\n",
    "variable_names = [\"A_\", \"B_\", \"C_\", \"D_\", \"E_\", \"F_\"]\n",
    "symbolic_eq = node_to_symbolic(eq, model, variable_names=variable_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
